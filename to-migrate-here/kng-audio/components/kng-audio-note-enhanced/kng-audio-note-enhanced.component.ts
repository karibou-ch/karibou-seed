import { Component, EventEmitter, Input, OnInit, Output, OnDestroy, ChangeDetectorRef, CUSTOM_ELEMENTS_SCHEMA } from '@angular/core';
import { Subscription } from 'rxjs';
import { KngAudioRecorderEnhancedService } from '../../services/kng-audio-recorder-enhanced.service';
import { AudioLabels, $i18n } from '../../services/kng-audio-i18n.service';
import { RecorderState, ErrorCase, AudioNoteType, AudioNoteState } from '../../interfaces/audio.interfaces';
import { KngAssistantAiService } from 'src/app/kng-assistant-ai.service';
import { CommonModule } from '@angular/common';
import { KngAudioVisualizerComponent } from '../kng-audio-visualizer.component';
import { TranscriptionAccumulator } from '../../services/kng-audio-transcription-accumulator';


// Types d√©j√† d√©finis dans interfaces/audio.interfaces.ts

@Component({
  selector: 'kng-audio-note-enhanced',
  templateUrl: './kng-audio-note-enhanced.component.html',
  styleUrls: ['./kng-audio-note-enhanced.component.scss'],
  standalone: true,
  imports: [CommonModule, KngAudioVisualizerComponent],
  schemas: [CUSTOM_ELEMENTS_SCHEMA]
})
export class KngAudioNoteEnhancedComponent implements OnInit, OnDestroy {

  // ‚úÖ Configuration
  @Input() type: AudioNoteType = 'item';
  @Input() hasCustomTitle: boolean = false;
  @Input() hasCustomDescription: boolean = false;
  @Input() hasCustomResponse: boolean = false;
  @Input() filename: string = '';
  @Input() disabled: boolean = false;
  // Uploadcare supprim√© - utilise maintenant /api/transcribe
  @Input() amount: number = 0;
  @Input() locale: string = 'fr';
  @Input() compact: boolean = false;
  @Input() displayTranscription: boolean = true;

  // ‚úÖ Events
  @Output() onAudioReady = new EventEmitter<{type: AudioNoteType, audioUrl: string, transcription: string, stream: boolean}>();
  @Output() onAudioError = new EventEmitter<{case: ErrorCase, message: string}>();
  @Output() onAudioLoading = new EventEmitter<boolean>();
  @Output() onStateChange = new EventEmitter<AudioNoteState>();

  // ‚úÖ √âtat interne (simplifi√© - pas de hasAudio car pas de persistance)
  audioState: AudioNoteState = {
    isRecording: false,
    isProcessing: false,
    hasError: false,
    canRetry: false,
    hasAudio: false, // Toujours false car pas de persistance
    started: false,
    chunkIndex: 0
  };

  audioTimeout: number = 60*5;

  // ‚úÖ √âtat transcription
  private isTranscribing = false;
  private transcriptionAccumulator = new TranscriptionAccumulator();

  recordingTime: number = 0;
  instanceId: string; // G√©n√©r√© automatiquement

  private subscription = new Subscription();
  private recordingTimer: any;

  // ‚úÖ Labels i18n
  public get $i18n(): AudioLabels {
    return $i18n[this.locale];
  }

  constructor(
    private $assistant: KngAssistantAiService,
    private $audioEnhanced: KngAudioRecorderEnhancedService,
    private cdr: ChangeDetectorRef
  ) {
    // ‚úÖ G√©n√©rer ID unique automatiquement
    this.instanceId = `audio-note-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  // ‚úÖ Getter pour l'√©tat processing complet (processing + transcription)
  get isProcessingOrTranscribing(): boolean {
    return this.audioState.isProcessing || this.isTranscribing;
  }

  ngOnInit() {
    this.setupAudioServiceListeners();
  }

  ngOnDestroy() {
    this.subscription.unsubscribe();
    if (this.recordingTimer) {
      clearInterval(this.recordingTimer);
    }
  }

  private setupAudioServiceListeners() {
    // ‚úÖ √âtats du recorder
    this.subscription.add(
      this.$audioEnhanced.recorderState.subscribe(state => {
        this.audioState.isRecording = state === RecorderState.RECORDING;
        this.audioState.isProcessing = state === RecorderState.PROCESSING;

        if (state === RecorderState.RECORDING) {
          this.startRecordingTimer();
        } else {
          this.stopRecordingTimer();
        }

        // ‚úÖ CORRECTION : Gestion auto-stop par d√©tection de silence
        if (state === RecorderState.SILENCE) {
          console.log('üîá Silence detected, stopping recording');
          this.stopRecording();
        }

        this.emitStateChange();
        this.cdr.detectChanges();
      })
    );

    // ‚úÖ Erreurs
    this.subscription.add(
      this.$audioEnhanced.recorderError.subscribe(error => {
        this.audioState.hasError = true;
        this.audioState.errorMessage = error.message;
        this.audioState.canRetry = error.retry || false;

        this.onAudioError.emit({ case: error.case, message: error.message });
        this.emitStateChange();
        this.cdr.detectChanges();
      })
    );
  }

  private startRecordingTimer() {
    this.recordingTime = 0;
    this.recordingTimer = setInterval(() => {
      this.recordingTime++;
      this.cdr.detectChanges();
    }, 1000);
  }

  private stopRecordingTimer() {
    if (this.recordingTimer) {
      clearInterval(this.recordingTimer);
      this.recordingTimer = null;
    }
  }

  private emitStateChange() {
    this.onStateChange.emit({ ...this.audioState });
  }

  // ‚úÖ API publique
  async toggleRecording() {
    if (this.audioState.isRecording) {
      await this.stopRecording();
    } else {
      await this.startRecording();
    }
  }

  private async startRecording() {
    try {
      this.dismissError();
      this.audioState.started = true;

      // ‚úÖ R√©initialiser la transcription accumul√©e
      this.transcriptionAccumulator.reset();
      this.audioState.transcription = '';
      this.audioState.chunkIndex = 0;

      // V√©rifier support et permissions
      if (!this.$audioEnhanced.isSupported) {
        throw new Error('Enregistrement audio non support√© par ce navigateur');
      }

      // D√©marrer enregistrement
      await this.$audioEnhanced.startRecording({
        timeout: this.audioTimeout * 1000,
        quality: 'medium',
        stopOnSilence: true,
        timeSlice: 16000, // 8 secondes
        onChunk: async (data) => {
          await this.processChunk(data.typedBlob, this.audioState.chunkIndex);
          this.audioState.chunkIndex++;
        }
      });

    } catch (error: any) {
      console.error('‚ùå Start recording failed:', error);
      this.audioState.hasError = true;
      this.audioState.errorMessage = error.message;
      this.audioState.canRetry = true;
      this.emitStateChange();
    }
  }

  private async stopRecording() {
    try {
      this.onAudioLoading.emit(true);

      const result = await this.$audioEnhanced.stopRecording();

      // ‚úÖ MODE CHUNK : En mode chunk, tous les chunks ont d√©j√† √©t√© trait√©s via processChunk()
      // Le blob peut √™tre undefined car les donn√©es ont √©t√© stream√©es
      if (!result.blob) {
        // En mode chunk, c'est normal - tous les chunks ont d√©j√† √©t√© transcrits
        this.isTranscribing = false;

        // ‚úÖ √âmettre le r√©sultat final avec la transcription accumul√©e
        const finalTranscription = this.transcriptionAccumulator.getFullText();
        this.audioState.transcription = finalTranscription;

        // this.onAudioReady.emit({
        //   type: this.type,
        //   audioUrl: '',
        //   transcription: finalTranscription,
        //   stream: false
        // });

        this.onAudioLoading.emit(false);
        this.emitStateChange();
        this.cdr.detectChanges();
        return;
      }

      // ‚úÖ MODE NORMAL : Si blob disponible, traiter normalement (fallback)
      const hasSound = await this.$audioEnhanced.detectSound({ blob: result.blob });
      if (!hasSound) {
        this.audioState.hasError = true;
        this.audioState.errorMessage = 'Aucun son d√©tect√© dans l\'enregistrement';
        this.audioState.canRetry = true;
        this.onAudioLoading.emit(false);
        this.emitStateChange();
        return;
      }

      // ‚úÖ Transcription compl√®te en mode normal (fallback si pas de chunks)
      await this.processWithWhisper(result.blob, '', result.duration, result.waveformData);

    } catch (error: any) {
      console.error('‚ùå Stop recording failed:', error);
      this.audioState.hasError = true;
      this.audioState.errorMessage = `Erreur d'enregistrement: ${error.message}`;
      this.audioState.canRetry = true;
      this.isTranscribing = false;
      this.onAudioLoading.emit(false);
      this.emitStateChange();
    }
  }

  private async processChunk(chunk: Blob, chunkIndex: number) {
    try {
      // D√©tecter le son
      const hasSound = await this.$audioEnhanced.detectSound({ blob: chunk });
      if (!hasSound && chunkIndex == 0) {
        this.audioState.hasError = true;
        this.audioState.errorMessage = 'Aucun son d√©tect√© dans l\'enregistrement';
        this.audioState.canRetry = true;
        this.onAudioLoading.emit(false);
        this.emitStateChange();
        return;
      }

      // ‚úÖ Transcription directe sans upload
      await this.processWithWhisper(chunk!);

    } catch (error: any) {
      console.error('‚ùå Stop recording failed:', error);
      this.audioState.hasError = true;
      this.audioState.errorMessage = `Erreur d'enregistrement: ${error.message}`;
      this.audioState.canRetry = true;
      this.onAudioLoading.emit(false);
      this.emitStateChange();
    }
  }

  // ‚úÖ uploadAndProcess supprim√© - transcription directe sans persistance

  private async processWithWhisper(audioBlob: Blob, audioUrl?: string, duration?: number, waveformData?: number[]) {
    try {
      // ‚úÖ D√©marrer l'√©tat transcription
      this.isTranscribing = true;
      this.cdr.detectChanges();

      // ‚úÖ Obtenir le prompt pour Whisper (derni√®re phrase comme contexte)
      const promptForWhisper = this.transcriptionAccumulator.getPromptForWhisper();

      // ‚úÖ Utiliser whisper du service assistant directement avec le blob
      const transcription = await this.$assistant.whisper({
        blob: audioBlob,
        type: this.type,
        silent: false,
        previousText: promptForWhisper
      });

      // ‚úÖ Ajouter la nouvelle transcription (1-2 phrases) √† l'accumulateur
      if (transcription && transcription.trim()) {
        this.transcriptionAccumulator.addTranscription(transcription.trim());
        this.audioState.transcription = this.transcriptionAccumulator.getFullText();
      }

      this.isTranscribing = false;

      // √âmettre le r√©sultat final
      this.onAudioReady.emit({
        type: this.type,
        audioUrl: '', // Pas d'URL persistante n√©cessaire
        transcription: this.audioState.transcription,
        stream: !!this.audioState.isRecording
      });

      this.emitStateChange();
      this.cdr.detectChanges();

    } catch (error: any) {
      console.error('‚ùå Whisper processing failed:', error);

      // ‚úÖ Arr√™ter l'√©tat transcription en cas d'erreur
      this.isTranscribing = false;
      this.audioState.transcription = '';

      // √âmettre l'audio sans transcription
      // this.onAudioReady.emit({
      //   type: this.type,
      //   audioUrl: '', // Pas d'URL persistante n√©cessaire
      //   transcription: '',
      //   stream: false
      // });

      this.cdr.detectChanges();
    }
  }

  // ‚úÖ M√©thodes panier supprim√©es - pas n√©cessaires pour transcription

  // ‚úÖ G√©n√©ration contexte simplifi√© (services externes supprim√©s)
  private async generateContext(): Promise<string> {
    // Context basique selon le type
    switch (this.type) {
      case 'support':
        return 'Demande de support client';
      case 'helper':
        return 'Assistance g√©n√©rale';
      case 'item':
        return 'Note sur un produit';
      default:
        return '';
    }
  }

  // ‚úÖ M√©thodes utilitaires (panier supprim√©)

  onRetry() {
    this.dismissError();
    this.startRecording();
  }

  dismissError() {
    this.audioState.hasError = false;
    this.audioState.errorMessage = undefined;
    this.audioState.canRetry = false;
    this.emitStateChange();
  }

  // ‚úÖ M√©thodes audio supprim√©es - pas de persistance n√©cessaire

  // ‚úÖ Helpers d'affichage avec i18n local
  getNoteTitle(): string {
    switch (this.type) {
      case 'prompt': return this.$i18n.title_prompt;
      case 'support': return this.$i18n.title_support;
      case 'helper': return this.$i18n.title_helper;
      default: return this.$i18n.title_prompt;
    }
  }

  getNoteDescription(): string {
    switch (this.type) {
      case 'prompt': return this.$i18n.desc_prompt;
      case 'support': return this.$i18n.desc_support;
      case 'helper': return this.$i18n.desc_helper;
      default: return this.$i18n.desc_prompt;
    }
  }

  getLoadingMessage(): string {
    if (this.audioState.isProcessing) {
      return this.$i18n.state_processing;
    }
    if (this.isTranscribing) {
      return this.$i18n.state_transcribing;
    }
    return this.$i18n.message_processing;
  }

  formatDuration(seconds: number): string {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  }
}
