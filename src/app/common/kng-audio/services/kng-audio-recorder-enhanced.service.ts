import { EventEmitter, Injectable } from '@angular/core';
import { RecordRTCPromisesHandler, StereoAudioRecorder } from "recordrtc";
import {
  RecordedAudioOutput,
  ErrorCase,
  RecorderState,
  AudioActivityData,
  AudioRecordingOptions
} from '../interfaces/audio.interfaces';
import { $i18n, AudioLabels } from './kng-audio-i18n.service';

/**
 * Service d'enregistrement audio avanc√© avec gestion des permissions et compatibilit√© multi-navigateurs
 *
 * @description
 * Service complet pour l'enregistrement audio avec:
 * - Gestion intelligente des permissions microphone
 * - D√©tection d'activit√© audio temps r√©el
 * - Support multi-navigateurs et multi-plateformes
 * - Gestion d'erreurs fine avec instructions utilisateur
 * - G√©n√©ration de donn√©es waveform pour visualisation
 *
 * @compatibility
 * ‚úÖ **Desktop:**
 * - Chrome 47+ (Windows/Mac/Linux)
 * - Firefox 55+ (Windows/Mac/Linux)
 * - Safari 11+ (macOS)
 * - Edge 79+ (Windows/Mac)
 *
 * ‚úÖ **Mobile:**
 * - Chrome Mobile 47+ (Android/iOS)
 * - Safari Mobile 11+ (iOS)
 * - Samsung Internet 5.0+ (Android)
 * - Firefox Mobile 68+ (Android)
 *
 * ‚ö†Ô∏è **Limitations connues:**
 * - Android Browser natif: navigator.permissions non support√© (fallback impl√©ment√©)
 * - iOS Safari < 11: getUserMedia non support√©
 * - WebView apps: permissions peuvent √™tre limit√©es selon l'app
 *
 * @example
 * ```typescript
 * // V√©rification support
 * if (!this.$audio.isSupported) {
 *   console.error('Navigateur non support√©');
 *   return;
 * }
 *
 * // Enregistrement simple
 * try {
 *   await this.$audio.startRecording({
 *     timeout: 30000,
 *     quality: 'medium'
 *   });
 *
 *   const result = await this.$audio.stopRecording();
 *   console.log('Audio enregistr√©:', result.duration, 'secondes');
 * } catch (error) {
 *   console.error('Erreur enregistrement:', error);
 * }
 * ```
 *
 * @author Karibou Team
 * @since 2024
 * @version 2.0.0
 */
@Injectable({
  providedIn: 'root'
})
export class KngAudioRecorderEnhancedService {

  // ‚úÖ AM√âLIORATION : Events plus d√©taill√©s
  public recorderError = new EventEmitter<{case: ErrorCase, message: string, retry?: boolean}>();
  public recorderState = new EventEmitter<RecorderState>();
  public audioActivity = new EventEmitter<AudioActivityData>();

  // ‚úÖ AM√âLIORATION : √âtats internes plus robustes
  private _recorderState: RecorderState = RecorderState.STOPPED;
  private _recordTime = 0;
  private _avgVolume = 0;
  private _recordTimeout: any = 0;
  private _retryCount = 0;
  private _maxRetries = 3;

  // ‚úÖ AM√âLIORATION : Gestion hardware
  private stream: MediaStream | null = null;
  private recorder: RecordRTCPromisesHandler | null = null;
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private animationFrame: number | null = null;

  // ‚úÖ MERGE: Ajout des champs pour gestion du mode chunk depuis to-migrate-here
  private _lastOptions?: AudioRecordingOptions;
  private _streamedBytes = 0;
  private _silenceDetectionActive = false; // Flag pour arr√™ter la d√©tection de silence

  // ‚úÖ AM√âLIORATION : Configuration
  private config = {
    sampleRate: 44100,
    channelCount: 1,
    bitRate: 128000,
    timeout: 15000,
    silenceTimeout: 3000,
    volumeThreshold: 0.01,
    silenceThreshold: 0.1  // ‚úÖ CORRECTION : Seuil plus √©lev√© (0.05 au lieu de 0.01)
  };

  // ‚úÖ NOUVEAU : Support i18n
  private locale: 'fr' | 'en' | string = 'fr';
  private get labels(): AudioLabels {
    return $i18n[this.locale];
  }

  constructor() {
    this._recorderState = RecorderState.STOPPED;
    // D√©tection automatique de la langue
    this.locale = (navigator.language.startsWith('fr')) ? 'fr' : 'en';
  }

  /**
   * Change la langue des messages d'erreur et instructions
   *
   * @param {string} locale - Langue: 'fr' ou 'en'
   *
   * @example
   * ```typescript
   * this.$audio.setLocale('en');
   * ```
   */
  setLocale(locale: 'fr' | 'en' | string): void {
    this.locale = locale;
  }

  /**
   * Ajuste le seuil de d√©tection du silence
   *
   * @param threshold - Nouveau seuil (0.0 √† 1.0)
   * @param timeout - Nouveau timeout en millisecondes (optionnel)
   *
   * @description
   * Permet d'ajuster dynamiquement la sensibilit√© de la d√©tection de silence.
   * Valeurs recommand√©es :
   * - 0.01 : Tr√®s sensible (d√©tecte le moindre bruit de fond)
   * - 0.05 : Sensibilit√© normale (recommand√©)
   * - 0.1 : Moins sensible (n√©cessite un silence plus marqu√©)
   *
   * @example
   * ```typescript
   * // Rendre la d√©tection moins sensible
   * audioService.configureSilenceDetection(0.1, 5000);
   * ```
   */
  configureSilenceDetection(threshold: number, timeout?: number): void {
    if (threshold < 0 || threshold > 1) {
      console.warn('‚ö†Ô∏è Silence threshold should be between 0 and 1');
      return;
    }

    this.config.silenceThreshold = threshold;
    if (timeout !== undefined) {
      this.config.silenceTimeout = timeout;
    }

    console.log(`üîá Silence detection configured - Threshold: ${threshold}, Timeout: ${this.config.silenceTimeout}ms`);
  }

  /**
   * Obtient les statistiques de volume actuelles
   *
   * @returns Objet avec les statistiques de volume ou null si pas d'enregistrement
   *
   * @description
   * Utile pour d√©boguer la d√©tection de silence et ajuster les seuils.
   *
   * @example
   * ```typescript
   * const stats = audioService.getVolumeStats();
   * if (stats) {
   *   console.log(`Volume: ${stats.average}, Max: ${stats.max}, Silence: ${stats.isSilent}`);
   * }
   * ```
   */
  getVolumeStats(): { average: number; max: number; min: number; isSilent: boolean } | null {
    if (!this.analyser || this.state !== RecorderState.RECORDING) {
      return null;
    }

    const bufferLength = this.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    this.analyser.getByteFrequencyData(dataArray);

    let sum = 0;
    let max = 0;
    let min = 255;

    for (let i = 0; i < bufferLength; i++) {
      const value = dataArray[i];
      sum += value;
      max = Math.max(max, value);
      min = Math.min(min, value);
    }

    const average = sum / bufferLength / 255;
    const normalizedMax = max / 255;
    const normalizedMin = min / 255;
    const isSilent = average < this.config.silenceThreshold;

    return {
      average: parseFloat(average.toFixed(4)),
      max: parseFloat(normalizedMax.toFixed(4)),
      min: parseFloat(normalizedMin.toFixed(4)),
      isSilent
    };
  }

  /**
   * √âtat actuel de l'enregistreur
   * @returns {RecorderState} √âtat: RECORDING, STOPPED, PAUSED, SILENCE, PROCESSING
   */
  get state(): RecorderState {
    return this._recorderState;
  }

  /**
   * Temps d'enregistrement en cours en secondes
   * @returns {number} Dur√©e en secondes depuis le d√©but de l'enregistrement
   */
  get recordTime(): number {
    if (!this._recordTime) {
      return 0;
    }
    return parseFloat(((Date.now() - this._recordTime) / 1000).toFixed(2));
  }

  /**
   * V√©rifie si le navigateur supporte l'enregistrement audio
   *
   * @description
   * Teste la disponibilit√© des APIs requises:
   * - navigator.mediaDevices.getUserMedia (acc√®s microphone)
   * - MediaRecorder (enregistrement audio)
   *
   * @compatibility
   * ‚úÖ Chrome 47+, Firefox 55+, Safari 11+, Edge 79+
   * ‚úÖ Chrome Mobile, Safari Mobile, Samsung Internet 5.0+
   * ‚ùå Internet Explorer (non support√©)
   * ‚ùå iOS Safari < 11 (non support√©)
   *
   * @returns {boolean} true si le navigateur supporte l'enregistrement audio
   *
   * @example
   * ```typescript
   * if (!this.$audio.isSupported) {
   *   this.showError('Votre navigateur ne supporte pas l\'enregistrement audio');
   *   return;
   * }
   * ```
   */
  get isSupported(): boolean {
    return !!(navigator.mediaDevices &&
             navigator.mediaDevices.getUserMedia &&
             (window as any).MediaRecorder);
  }

  /**
   * Ferme proprement le flux audio et lib√®re les ressources
   *
   * @description
   * Nettoie toutes les ressources audio:
   * - Arr√™te l'enregistrement en cours
   * - Ferme le contexte audio
   * - Lib√®re les tracks du stream
   * - Annule les animations en cours
   *
   * @compatibility
   * ‚úÖ Tous navigateurs support√©s
   *
   * @example
   * ```typescript
   * // Nettoyage manuel (optionnel, fait automatiquement)
   * await this.$audio.closeAudioStream();
   * ```
   *
   * @note MERGE: Am√©liorations iOS depuis to-migrate-here (async + meilleure gestion tracks)
   */
  async closeAudioStream(): Promise<void> {
    try {
      // Stop animation frame
      if (this.animationFrame) {
        cancelAnimationFrame(this.animationFrame);
        this.animationFrame = null;
      }

      // Stop recorder
      if (this.recorder) {
        try {
          await this.recorder.stopRecording();
        } catch (err) {
          console.warn('‚ö†Ô∏è Recorder stop error (ignored):', err);
        }
        this.recorder = null;
      }

      // ‚úÖ MERGE iOS: Arr√™ter TOUS les tracks du stream, m√™me si !active
      if (this.stream) {
        const tracks = this.stream.getTracks();
        tracks.forEach(track => {
          // Forcer l'arr√™t m√™me si d√©j√† stopped
          if (track.readyState !== 'ended') {
            track.stop();
            console.log('üé§ Audio track stopped:', track.kind, track.readyState);
          }
        });
        this.stream = null;
      }

      // ‚úÖ MERGE iOS: Await close() pour garantir fermeture compl√®te
      if (this.audioContext && this.audioContext.state !== 'closed') {
        try {
          await this.audioContext.close();
          console.log('üîä AudioContext closed successfully');
        } catch (err) {
          console.warn('‚ö†Ô∏è AudioContext close error (ignored):', err);
        }
        this.audioContext = null;
      }

      this.analyser = null;
    } catch (error) {
      console.error('‚ùå Error closing audio stream:', error);
    }
  }

  // ‚úÖ AM√âLIORATION : D√©tection volume temps r√©el avec visualisation
  private startVolumeDetection(): void {
    if (!this.audioContext || !this.analyser || !this.stream) return;

    const bufferLength = this.analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    const detectVolume = () => {
      if (this.state !== RecorderState.RECORDING) {
        return;
      }

      this.analyser!.getByteFrequencyData(dataArray);

      // Calculate volume
      let sum = 0;
      let max = 0;
      for (let i = 0; i < bufferLength; i++) {
        const amplitude = dataArray[i] / 255;
        sum += amplitude * amplitude;
        max = Math.max(max, amplitude);
      }

      const volume = Math.sqrt(sum / bufferLength);
      const frequency = max;

      this._avgVolume = (volume + this._avgVolume) / 2;

      // ‚úÖ NOUVEAU : √âmission activit√© audio pour visualisation
      const activityData: AudioActivityData = {
        volume,
        frequency,
        timestamp: Date.now(),
        isActive: volume > this.config.volumeThreshold
      };

      this.audioActivity.emit(activityData);

      // Continue monitoring
      this.animationFrame = requestAnimationFrame(detectVolume);
    };

    detectVolume();
  }

  /**
   * D√©tecte la pr√©sence de son dans un fichier audio
   *
   * @description
   * Analyse un fichier audio pour d√©tecter la pr√©sence de contenu sonore.
   * Utilise une analyse par segments pour √©viter les faux positifs.
   *
   * @param {Object} content - Contenu audio √† analyser
   * @param {Blob} [content.blob] - Blob audio √† analyser
   * @param {string} [content.url] - URL du fichier audio √† analyser
   *
   * @returns {Promise<boolean>} true si du son est d√©tect√©
   *
   * @compatibility
   * ‚úÖ Chrome 47+, Firefox 55+, Safari 11+, Edge 79+
   * ‚úÖ Tous navigateurs mobiles support√©s
   *
   * @example
   * ```typescript
   * const hasSound = await this.$audio.detectSound({blob: audioBlob});
   * if (!hasSound) {
   *   console.log('Aucun son d√©tect√© dans l\'enregistrement');
   * }
   * ```
   *
   * @note MERGE: Am√©liorations depuis to-migrate-here (meilleure gestion des segments + finally)
   */
  async detectSound(content: {blob?: Blob, url?: string}): Promise<boolean> {
    const AudioCtx = window.AudioContext || (window as any).webkitAudioContext;
    const audioCtx = new AudioCtx();

    try {
      let arrayBuffer: ArrayBuffer;

      if (content.url) {
        const response = await fetch(content.url);
        arrayBuffer = await response.arrayBuffer();
      } else if (content.blob) {
        arrayBuffer = await content.blob.arrayBuffer();
      } else {
        return false;
      }

      const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      const floats32 = audioBuffer.getChannelData(0);

      // ‚ö†Ô∏è Audio vide ‚Üí pas de son
      if (!floats32.length) {
        console.log('üîä Audio analysis: empty buffer, result: false');
        return false;
      }

      let maxVolume = 0;
      let activeSegments = 0;

      // ‚úÖ MERGE: Toujours un segmentSize >= 1
      const targetSegments = 100;
      const segmentSize = Math.max(1, Math.floor(floats32.length / targetSegments));

      let segmentsCount = 0;

      for (let i = 0; i < floats32.length; i += segmentSize) {
        const start = i;
        const end = Math.min(i + segmentSize, floats32.length);
        const effectiveSize = end - start;

        if (effectiveSize <= 0) {
          continue;
        }

        let segmentSum = 0;

        for (let j = start; j < end; j++) {
          const amplitude = Math.abs(floats32[j]);
          segmentSum += amplitude * amplitude;
          maxVolume = Math.max(maxVolume, amplitude);
        }

        const segmentVolume = Math.sqrt(segmentSum / effectiveSize);

        if (segmentVolume > this.config.volumeThreshold) {
          activeSegments++;
        }

        segmentsCount++;
      }

      const ratio = segmentsCount > 0 ? activeSegments / segmentsCount : 0;
      const isActive = ratio > 0.05 && maxVolume > this.config.volumeThreshold;

      console.log(
        `üîä Audio analysis: ${Math.round(ratio * 100)}% active segments, ` +
        `max: ${maxVolume.toFixed(3)}, result: ${isActive}`
      );

      return isActive;

    } catch (error) {
      console.error('‚ùå Error detecting sound:', error);
      return false;
    } finally {
      // ‚úÖ MERGE: Toujours fermer l'AudioContext
      try {
        await audioCtx.close();
        console.log('üîä detectSound AudioContext closed');
      } catch (err) {
        console.warn('‚ö†Ô∏è detectSound AudioContext close error:', err);
      }
    }
  }

  /**
   * @deprecated Utiliser isSupported √† la place
   *
   * @description
   * ‚ö†Ô∏è DEPRECATED: Cette m√©thode est un lazy check qui ne v√©rifie pas r√©ellement les permissions.
   * Utiliser `isSupported` pour v√©rifier le support navigateur.
   * Les permissions sont demand√©es automatiquement lors de `startRecording()`.
   *
   * @returns {Promise<boolean>} Retourne la valeur de isSupported
   *
   * @see {@link isSupported} Pour v√©rifier le support navigateur
   * @see {@link getPermissionState} Pour v√©rifier l'√©tat des permissions (debug)
   */
  async isAudioGranted(): Promise<boolean> {
    console.warn('‚ö†Ô∏è isAudioGranted is deprecated - use isSupported instead. Permission will be requested on startRecording()');
    return this.isSupported;
  }

  /**
   * Obtient l'√©tat actuel des permissions microphone (pour debug)
   *
   * @description
   * V√©rifie l'√©tat des permissions sans d√©clencher de demande.
   * ‚ö†Ô∏è ATTENTION: navigator.permissions pas support√© sur Android Browser natif.
   *
   * @returns {Promise<string>} √âtat: 'granted', 'denied', 'prompt', 'unknown'
   *
   * @compatibility
   * ‚úÖ Chrome 47+, Firefox 55+, Safari 16+, Edge 79+
   * ‚ùå Android Browser natif (retourne 'prompt')
   * ‚ùå iOS Safari < 16 (retourne 'prompt')
   *
   * @example
   * ```typescript
   * const state = await this.$audio.getPermissionState();
   * console.log('Permission state:', state);
   * ```
   */
  async getPermissionState(): Promise<'granted' | 'denied' | 'prompt' | 'unknown'> {
    if (!this.isSupported) {
      return 'unknown';
    }

    try {
      // ‚ö†Ô∏è ATTENTION : navigator.permissions pas support√© sur Android Browser
      const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      return permission.state as 'granted' | 'denied' | 'prompt';
    } catch {
      // Fallback: assume permission needed (safer approach)
      return 'prompt';
    }
  }

  /**
   * Demande explicitement la permission microphone apr√®s annulation
   *
   * @description
   * Tente d'obtenir la permission microphone de fa√ßon explicite.
   * Utile apr√®s une annulation utilisateur (Escape) ou un refus initial.
   *
   * @returns {Promise<Object>} R√©sultat avec success boolean et error optionnel
   *
   * @compatibility
   * ‚úÖ Chrome 47+, Firefox 55+, Safari 11+, Edge 79+
   * ‚úÖ Chrome Mobile, Safari Mobile, Samsung Internet 5.0+
   * ‚ö†Ô∏è Certains navigateurs n√©cessitent un rechargement de page apr√®s refus
   *
   * @example
   * ```typescript
   * const result = await this.$audio.requestPermissionExplicitly();
   * if (result.success) {
   *   console.log('Permission accord√©e');
   * } else {
   *   console.error('Permission refus√©e:', result.error);
   * }
   * ```
   */
  async requestPermissionExplicitly(): Promise<{success: boolean, error?: string}> {
    if (!this.isSupported) {
      return {
        success: false,
        error: this.labels.system_navigator_not_supported
      };
    }

    try {
      const testStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      testStream.getTracks().forEach(track => track.stop());
      return {success: true};
    } catch (err: any) {
      return {
        success: false,
        error: this.getDetailedErrorMessage(err)
      };
    }
  }

  /**
   * Obtient le flux audio du microphone avec gestion d'erreurs avanc√©e
   *
   * @description
   * Acquiert l'acc√®s au microphone et configure le contexte audio.
   * G√®re automatiquement les permissions et fournit des messages d'erreur d√©taill√©s.
   *
   * @returns {Promise<MediaStream>} Flux audio du microphone
   * @throws {Error} Erreur avec message d√©taill√© selon le type de probl√®me
   *
   * @compatibility
   * ‚úÖ Chrome 47+, Firefox 55+, Safari 11+, Edge 79+
   * ‚úÖ Chrome Mobile, Safari Mobile, Samsung Internet 5.0+
   * ‚ö†Ô∏è iOS Safari n√©cessite interaction utilisateur (geste tactile/clic)
   *
   * @example
   * ```typescript
   * try {
   *   const stream = await this.$audio.getAudioStream();
   *   console.log('Microphone accessible');
   * } catch (error) {
   *   console.error('Erreur microphone:', error.message);
   * }
   * ```
   */
  async getAudioStream(): Promise<MediaStream> {
    if (this.stream && this.stream.active) {
      return this.stream;
    }

    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: this.config.sampleRate,
          channelCount: this.config.channelCount,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      // ‚úÖ AM√âLIORATION : Setup audio context pour monitoring
      const AudioCtx = window.AudioContext || (window as any).webkitAudioContext;
      this.audioContext = new AudioCtx();
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 256;
      this.analyser.smoothingTimeConstant = 0.8;

      const source = this.audioContext.createMediaStreamSource(this.stream);
      source.connect(this.analyser);

      console.log('üé§ Audio stream acquired successfully');
      return this.stream;

    } catch (err: any) {
      console.error('‚ùå Error accessing audio stream:', err);

      const errorDetails = this.getDetailedErrorInfo(err);
      this.recorderError.emit(errorDetails);
      throw err;
    }
  }

  // ‚úÖ NOUVEAU : Gestion d'erreurs fine avec instructions utilisateur
  private getDetailedErrorInfo(err: any): {case: ErrorCase, message: string, retry: boolean, instructions?: string} {
    let errorCase = ErrorCase.HARDWARE_ERROR;
    let message = this.labels.error_hardware_error;
    let retry = true;
    let instructions = '';

    switch (err.name) {
      case 'NotAllowedError':
      case 'PermissionDeniedError':
        errorCase = ErrorCase.USER_CONSENT_FAILED;
        message = this.labels.error_permission_denied;
        retry = true; // ‚úÖ CORRECTION : Permettre retry m√™me pour permission denied
        instructions = this.getPermissionInstructions();
        break;

      case 'NotFoundError':
      case 'DevicesNotFoundError':
        errorCase = ErrorCase.HARDWARE_ERROR;
        message = this.labels.error_microphone_not_found;
        retry = false;
        instructions = this.labels.instructions_microphone_connect;
        break;

      case 'NotReadableError':
      case 'TrackStartError':
        errorCase = ErrorCase.HARDWARE_ERROR;
        message = this.labels.error_microphone_occupied;
        retry = true;
        instructions = this.labels.instructions_microphone_close_apps;
        break;

      case 'OverconstrainedError':
      case 'ConstraintNotSatisfiedError':
        errorCase = ErrorCase.HARDWARE_ERROR;
        message = this.labels.error_microphone_config;
        retry = false;
        instructions = this.labels.instructions_microphone_config;
        break;

      case 'TypeError':
        errorCase = ErrorCase.BROWSER_NOT_SUPPORTED;
        message = this.labels.error_technical;
        retry = false;
        instructions = this.labels.instructions_technical_support;
        break;

      default:
        errorCase = ErrorCase.HARDWARE_ERROR;
        message = this.labels.error_unknown;
        retry = true;
        instructions = this.labels.instructions_retry_later;
        break;
    }

    return { case: errorCase, message, retry, instructions };
  }

  /**
   * G√©n√®re des instructions sp√©cifiques selon le navigateur pour autoriser le microphone
   *
   * @private
   * @description
   * D√©tecte le navigateur utilis√© et retourne des instructions pr√©cises
   * pour autoriser l'acc√®s au microphone dans les param√®tres.
   *
   * @returns {string} Instructions d√©taill√©es selon le navigateur
   *
   * @compatibility
   * ‚úÖ Instructions pour: Chrome, Firefox, Safari, Edge, autres
   */
  private getPermissionInstructions(): string {
    const userAgent = navigator.userAgent.toLowerCase();

    if (userAgent.includes('chrome')) {
      return this.labels.instructions_chrome;
    } else if (userAgent.includes('firefox')) {
      return this.labels.instructions_firefox;
    } else if (userAgent.includes('safari')) {
      return this.labels.instructions_safari;
    } else if (userAgent.includes('edge')) {
      return this.labels.instructions_edge;
    } else if (userAgent.includes('samsungbrowser')) {
      return this.labels.instructions_samsung;
    } else {
      return this.labels.instructions_generic;
    }
  }

  // ‚úÖ NOUVEAU : Message d'erreur simple pour requestPermissionExplicitly
  private getDetailedErrorMessage(err: any): string {
    switch (err.name) {
      case 'NotAllowedError':
      case 'PermissionDeniedError':
        return this.labels.system_permission_retry;
      case 'NotFoundError':
        return this.labels.error_microphone_not_found;
      case 'NotReadableError':
        return this.labels.error_microphone_occupied;
      default:
        return this.labels.error_hardware_error;
    }
  }

  /**
   * D√©marre l'enregistrement audio avec options avanc√©es
   *
   * @description
   * Lance l'enregistrement audio avec configuration personnalisable:
   * - Qualit√© audio (low/medium/high)
   * - Timeout automatique
   * - D√©tection de silence
   * - Streaming temps r√©el par chunks
   *
   * @param {AudioRecordingOptions} [options={}] Options d'enregistrement
   * @param {number} [options.timeout] Timeout en ms (d√©faut: 15000)
   * @param {number} [options.timeSlice] Intervalle chunks en ms
   * @param {Function} [options.onChunk] Callback pour chunks temps r√©el
   * @param {boolean} [options.stopOnSilence] Arr√™t automatique sur silence
   * @param {'low'|'medium'|'high'} [options.quality='medium'] Qualit√© audio
   *
   * @returns {Promise<void>} Promise r√©solue quand l'enregistrement d√©marre
   * @throws {Error} Erreur si enregistrement impossible
   *
   * @compatibility
   * ‚úÖ Chrome 47+, Firefox 55+, Safari 11+, Edge 79+
   * ‚úÖ Chrome Mobile, Safari Mobile, Samsung Internet 5.0+
   * ‚ö†Ô∏è iOS Safari: n√©cessite interaction utilisateur pour d√©marrer
   *
   * @example
   * ```typescript
   * // Enregistrement simple
   * await this.$audio.startRecording();
   *
   * // Enregistrement avec options
   * await this.$audio.startRecording({
   *   timeout: 30000,
   *   quality: 'high',
   *   stopOnSilence: true
   * });
   *
   * // Streaming temps r√©el
   * await this.$audio.startRecording({
   *   timeSlice: 1000,
   *   onChunk: (data) => {
   *     console.log('Chunk re√ßu:', data.typedBlob.size, 'bytes');
   *   }
   * });
   * ```
   */
  async startRecording(options: AudioRecordingOptions = {}): Promise<void> {
    if (this._recorderState === RecorderState.RECORDING) {
      this.recorderError.emit({
        case: ErrorCase.ALREADY_RECORDING,
        message: this.labels.error_already_recording
      });
      return;
    }

    try {
      this._recordTime = Date.now();
      this._recorderState = RecorderState.RECORDING;
      // ‚úÖ MERGE: Tracking des options et bytes stream√©s depuis to-migrate-here
      this._lastOptions = options;
      this._streamedBytes = 0;

      this.stream = await this.getAudioStream();

      // ‚úÖ Configuration qualit√© (conserv√©e pour compatibilit√©)
      const qualityConfig = {
        low: { bitRate: 64000, sampleRate: 22050 },
        medium: { bitRate: 128000, sampleRate: 44100 },
        high: { bitRate: 256000, sampleRate: 48000 }
      };

      const quality = qualityConfig[options.quality || 'medium'];

      // ‚úÖ MIGRATION: Format WAV PCM 16-bit optimal pour transcription Whisper
      // StereoAudioRecorder force le format WAV coh√©rent avec l'API de transcription
      const mimeType = 'audio/wav';
      console.log('üéµ Format audio forc√©:', mimeType, '(WAV PCM 16-bit)');

      // ‚úÖ Configuration RecordRTC optimis√©e pour transcription
      const rtcOptions: any = {
        type: 'audio' as const,
        mimeType,
        recorderType: StereoAudioRecorder,  // ‚úÖ Force WAV format
        numberOfAudioChannels: 1,           // Mono pour transcription
        desiredSampRate: 16000,             // 16kHz optimal pour Whisper
        bitsPerSecond: 16,                  // 16-bit PCM
        debugger: false
      };

      // Ajout des options de configuration
      if (options.timeSlice) {
        rtcOptions.timeSlice = options.timeSlice;
      }

      // ‚úÖ MERGE: Gestion chunks temps r√©el avec comptabilisation des bytes stream√©s
      if (options.onChunk && options.timeSlice) {
        rtcOptions.ondataavailable = async (blob: Blob) => {
          console.log('üéµ ondataavailable', blob.size, 'bytes');
          const typedBlob = new Blob([blob], { type: mimeType });

          // Comptabiliser ce qui a d√©j√† √©t√© stream√©
          this._streamedBytes += typedBlob.size;

          const base64 = await this.blobToBase64(typedBlob);
          await options.onChunk!({ typedBlob, base64 });
        };
      }

      this.recorder = new RecordRTCPromisesHandler(this.stream, rtcOptions);
      await this.recorder.startRecording();

      // Start volume monitoring
      this.startVolumeDetection();

      this.recorderState.emit(this._recorderState);

      // ‚úÖ AM√âLIORATION : Timeout avec cleanup
      if (options.timeout) {
        this._recordTimeout = setTimeout(() => {
          console.log('‚è∞ Recording timeout reached');
          this.recorderState.emit(RecorderState.SILENCE);
        }, options.timeout);
      }

      // ‚úÖ AM√âLIORATION : D√©tection silence optionnelle
      if (options.stopOnSilence) {
        this.startSilenceDetection();
      }

      console.log('üé§ Recording started successfully');

    } catch (err: any) {
      console.error('‚ùå Recording start failed:', err);
      await this.clear();

      this.recorderError.emit({
        case: ErrorCase.HARDWARE_ERROR,
        message: `${this.labels.error_hardware_error}: ${err.message}`,
        retry: true
      });

      throw err;
    }
  }

  /**
   * Arr√™te l'enregistrement et retourne les donn√©es audio
   *
   * @description
   * Termine l'enregistrement en cours et retourne:
   * - Blob audio encod√©
   * - Donn√©es base64 pour upload
   * - Dur√©e d'enregistrement
   * - Donn√©es waveform pour visualisation
   *
   * @returns {Promise<Object>} Donn√©es d'enregistrement
   * @returns {Blob} [returns.blob] Fichier audio encod√©
   * @returns {string} [returns.base64] Donn√©es base64 pour upload
   * @returns {number} returns.duration Dur√©e en secondes
   * @returns {number[]} [returns.waveformData] Points waveform pour visualisation
   *
   * @compatibility
   * ‚úÖ Chrome 47+, Firefox 55+, Safari 11+, Edge 79+
   * ‚úÖ Tous navigateurs mobiles support√©s
   *
   * @example
   * ```typescript
   * const result = await this.$audio.stopRecording();
   * console.log(`Enregistrement: ${result.duration}s, ${result.blob?.size} bytes`);
   *
   * if (result.waveformData) {
   *   this.displayWaveform(result.waveformData);
   * }
   * ```
   */
  /**
   * @note MERGE: Am√©lioration mode chunk depuis to-migrate-here
   * En mode chunk avec timeSlice, les donn√©es sont d√©j√† √©mises via ondataavailable
   * Le blob final peut √™tre vide ou ne pas exister car toutes les donn√©es ont √©t√© stream√©es
   */
  async stopRecording(): Promise<{blob?: Blob, base64?: string, duration: number, waveformData?: number[]}> {
    //
    // ‚úÖ MERGE: Annuler imm√©diatement les timers et d√©tection de silence
    clearTimeout(this._recordTimeout);
    this._silenceDetectionActive = false;

    const duration = this.recordTime;
    this._recordTime = 0;
    this._recordTimeout = 0;

    if (this._recorderState === RecorderState.STOPPED) {
      return { duration };
    }

    try {
      this._recorderState = RecorderState.PROCESSING;
      this.recorderState.emit(this._recorderState);

      if (!this.recorder) {
        throw new Error('No recorder instance');
      }

      const options = this._lastOptions;
      const isChunkMode = !!(options?.onChunk && options.timeSlice);

      await this.recorder.stopRecording();
      const blob = await this.recorder.getBlob();

      // ‚úÖ MERGE MODE CHUNK : En mode chunk avec timeSlice, les donn√©es sont d√©j√† √©mises via ondataavailable
      // Le blob final peut √™tre vide ou ne pas exister car toutes les donn√©es ont √©t√© stream√©es
      if (isChunkMode) {
        console.log('üì¶ Stop recording in chunk mode - all chunks already emitted via ondataavailable');

        try {
          // V√©rifier s'il reste des donn√©es non stream√©es
          if (blob && blob.size > 0 && blob.size >= 44) {
            // ‚úÖ V√©rifier que le chunk final est assez grand pour √™tre un WAV valide (min 44 bytes header)
            // Les chunks trop petits ne sont pas des WAV valides et causent des erreurs serveur
            console.log(`üì¶ Emitting final partial chunk: ${blob.size} bytes`, blob.type);
            const lastTyped = new Blob([blob], { type: blob.type });
            const lastBase64 = await this.blobToBase64(lastTyped);
            await options!.onChunk!({ typedBlob: lastTyped, base64: lastBase64 });
          }
        } catch (err) {
          console.log('‚ö†Ô∏è No final blob available in chunk mode (expected behavior)');
        }

        // En mode chunk, on ne retourne pas de blob car tout a d√©j√† √©t√© trait√©
        return { duration };
      }

      // ‚úÖ MODE NORMAL : Sans timeSlice, obtenir le blob complet normalement
      if (!blob || blob.size === 0) {
        console.warn('‚ö†Ô∏è Empty blob after stopRecording - this should not happen in normal mode');
        return { duration };
      }

      const base64 = await this.recorder.getDataURL();

      // G√©n√©ration waveform data pour visualisation
      const waveformData = await this.generateWaveformData(blob);

      console.log('‚úÖ Recording stopped successfully', {
        duration,
        size: blob.size,
        type: blob.type,
        waveformPoints: waveformData?.length
      });

      return {
        blob,
        base64,
        duration,
        waveformData
      };

    } catch (err: any) {
      console.error('‚ùå Recording stop failed:', err);
      this.recorderError.emit({
        case: ErrorCase.HARDWARE_ERROR,
        message: `${this.labels.error_hardware_error}: ${err.message}`
      });

      return { duration };

    } finally {
      this._recorderState = RecorderState.STOPPED;
      this.recorderState.emit(this._recorderState);

      // ‚úÖ MERGE: Reset des infos de streaming
      this._lastOptions = undefined;
      this._streamedBytes = 0;

      await this.clear();
    }
  }

  // ‚úÖ MERGE: G√©n√©ration donn√©es waveform pour visualisation avec garantie fermeture AudioContext
  private async generateWaveformData(blob: Blob, points: number = 100): Promise<number[]> {
    const AudioCtx = window.AudioContext || (window as any).webkitAudioContext;
    const audioCtx = new AudioCtx();

    try {
      const arrayBuffer = await blob.arrayBuffer();
      const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      const channelData = audioBuffer.getChannelData(0);

      const samplesPerPoint = Math.floor(channelData.length / points);
      const waveformData: number[] = [];

      for (let i = 0; i < points; i++) {
        const start = i * samplesPerPoint;
        const end = Math.min(start + samplesPerPoint, channelData.length);

        let max = 0;
        for (let j = start; j < end; j++) {
          max = Math.max(max, Math.abs(channelData[j]));
        }

        waveformData.push(max);
      }

      return waveformData;

    } catch (error) {
      console.error('‚ùå Error generating waveform data:', error);
      return [];
    } finally {
      // ‚úÖ MERGE iOS : Garantir fermeture dans finally (m√™me en cas d'erreur)
      try {
        await audioCtx.close();
        console.log('üîä generateWaveform AudioContext closed');
      } catch (err) {
        console.warn('‚ö†Ô∏è generateWaveform AudioContext close error:', err);
      }
    }
  }

  // ‚úÖ MERGE: D√©tection silence plus sophistiqu√©e avec flag d'arr√™t imm√©diat
  private startSilenceDetection(): void {
    if (!this.audioContext || !this.analyser) {
      console.warn('üîá Silence detection: AudioContext ou Analyser non disponible');
      return;
    }

    //
    // ‚úÖ MERGE: Activer le flag de d√©tection
    this._silenceDetectionActive = true;

    let silenceStart = 0;
    const silenceThreshold = this.config.silenceThreshold; // ‚úÖ Utilise config centralis√©e
    const silenceTimeout = this.config.silenceTimeout;
    let logCounter = 0; // Pour √©viter trop de logs

    const checkSilence = () => {
      //
      // ‚úÖ MERGE: V√©rifier le flag en plus de l'√©tat pour arr√™t imm√©diat
      if (!this._silenceDetectionActive || this.state !== RecorderState.RECORDING) {
        console.log('üîá Silence detection stopped - flag:', this._silenceDetectionActive, 'state:', this.state);
        return;
      }

      const bufferLength = this.analyser!.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      this.analyser!.getByteFrequencyData(dataArray);

      let sum = 0;
      for (let i = 0; i < bufferLength; i++) {
        sum += dataArray[i];
      }
      const average = sum / bufferLength / 255;

      // ‚úÖ LOGS D√âTAILL√âS : Log toutes les 10 mesures (1 seconde)
      logCounter++;

      if (average < silenceThreshold) {
        if (silenceStart === 0) {
          silenceStart = Date.now();
        } else {
          const silenceDuration = Date.now() - silenceStart;
          if (silenceDuration > silenceTimeout) {
            this.recorderState.emit(RecorderState.SILENCE);
            return;
          } else {
            // Log progression du silence
            if (silenceDuration % 500 === 0) { // Toutes les 500ms
            }
          }
        }
      } else {
        silenceStart = 0;
      }

      setTimeout(checkSilence, 100);
    };

    checkSilence();
  }

  /**
   * Convertit un Blob en cha√Æne base64
   *
   * @description
   * Convertit un fichier Blob en repr√©sentation base64 pour upload ou stockage.
   * G√®re les erreurs de lecture et de conversion.
   *
   * @param {Blob} blob - Blob √† convertir
   * @returns {Promise<string>} Cha√Æne base64 (avec pr√©fixe data:)
   * @throws {Error} Erreur si conversion impossible
   *
   * @compatibility
   * ‚úÖ Tous navigateurs support√©s (FileReader API universelle)
   *
   * @example
   * ```typescript
   * const base64 = await this.$audio.blobToBase64(audioBlob);
   * console.log('Base64 length:', base64.length);
   * ```
   */
  async blobToBase64(blob: Blob): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        if (typeof reader.result === 'string') {
          resolve(reader.result);
        } else {
          reject(new Error('Failed to convert blob to base64'));
        }
      };
      reader.onerror = () => reject(new Error('FileReader error'));
      reader.readAsDataURL(blob);
    });
  }

  /**
   * M√©canisme de retry avec backoff exponentiel
   *
   * @description
   * Ex√©cute une op√©ration avec retry automatique en cas d'√©chec.
   * Utilise un backoff exponentiel pour espacer les tentatives.
   *
   * @template T
   * @param {Function} operation - Fonction √† ex√©cuter avec retry
   * @param {number} [maxRetries=3] - Nombre maximum de tentatives
   * @returns {Promise<T>} R√©sultat de l'op√©ration
   * @throws {Error} Derni√®re erreur si toutes les tentatives √©chouent
   *
   * @compatibility
   * ‚úÖ Tous navigateurs support√©s
   *
   * @example
   * ```typescript
   * const result = await this.$audio.retryOperation(
   *   () => this.getAudioStream(),
   *   3
   * );
   * ```
   */
  async retryOperation<T>(operation: () => Promise<T>, maxRetries: number = this._maxRetries): Promise<T> {
    let lastError: Error;

    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error as Error;
        console.warn(`‚ö†Ô∏è Attempt ${attempt + 1} failed:`, error);

        if (attempt < maxRetries) {
          // Wait before retry (exponential backoff)
          await new Promise(resolve => setTimeout(resolve, Math.pow(2, attempt) * 1000));
        }
      }
    }

    throw lastError!;
  }

  // ‚úÖ MERGE: Cleanup complet avec reset du flag de silence
  private async clear(): Promise<void> {
    this._silenceDetectionActive = false;
    await this.closeAudioStream();
    this._recorderState = RecorderState.STOPPED;
    this._avgVolume = 0;
    this._retryCount = 0;
  }
}
